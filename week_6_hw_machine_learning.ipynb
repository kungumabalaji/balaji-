{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMAVGIIL+bkwj/7nn9Ai5qh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kungumabalaji/balaji-/blob/main/week_6_hw_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tCa64cJmaZf",
        "outputId": "e198323d-8e33-4cff-b84b-c6fb40508bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch    # dl library\n",
        "import torch.nn as nn # neural network tools\n",
        "import torch.optim as optim # optimization algorithms SGD or Adam to improve the model.\n",
        "import numpy  as np\n",
        "import matplotlib as plt\n",
        "from torchvision import datasets,transforms # datasets"
      ],
      "metadata": {
        "id": "22QuGYV7mtA4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kpQF2RLvtOAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "38e7xsm-rXMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and transform the dta\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  #  hepls to converts imgae to pytorch,umerical data that the model understands).\n",
        "    transforms.Normalize((0.5,),(0.5)) # centre the pixcel value ble -1, 1 , 0.5 , 0.5 means it sub from every pixel value and divide by 0.5\n",
        "])"
      ],
      "metadata": {
        "id": "aK_1evqxqLQ8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root='./data',train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.DataLoader(train_data,batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "7dvpgO-BsCBV",
        "outputId": "c94c277f-c1c7-424f-da3f-1e7cf3003902"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 37.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.93MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torch.utils' has no attribute 'DataLoader'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cd51b2fd8222>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.utils' has no attribute 'DataLoader'"
          ]
        }
      ]
    },
    {
      "source": [
        "import torch    # dl library\n",
        "import torch.nn as nn # neural network tools\n",
        "import torch.optim as optim # optimization algorithms SGD or Adam to improve the model.\n",
        "import numpy  as np\n",
        "import matplotlib as plt\n",
        "from torchvision import datasets,transforms # datasets\n",
        "from torch.utils.data import DataLoader # Import DataLoader from the correct module\n",
        "\n",
        "\n",
        "# load and transform the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  #  hepls to converts imgae to pytorch,umerical data that the model understands).\n",
        "    transforms.Normalize((0.5,),(0.5)) # centre the pixcel value ble -1, 1 , 0.5 , 0.5 means it sub from every pixel value and divide by 0.5\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root='./data',train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_data,batch_size=32, shuffle=True) # Use DataLoader"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "MwOiqVAOxkKq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and transform the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  #  hepls to converts imgae to pytorch,umerical data that the model understands).\n",
        "    transforms.Normalize((0.5,),(0.5)) # centre the pixcel value ble -1, 1 , 0.5 , 0.5 means it sub from every pixel value and divide by 0.5\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root='./data',train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_data,batch_size=32, shuffle=True) # Use DataLoader"
      ],
      "metadata": {
        "id": "RDFQoWoIxquE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.MNIST(root='.data',train=False,transform=transform, download=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90xGxqCTxytN",
        "outputId": "f5890439-3748-4898-dcd9-d8085a9575c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to .data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 42.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/MNIST/raw/train-images-idx3-ubyte.gz to .data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to .data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.07MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/MNIST/raw/train-labels-idx1-ubyte.gz to .data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to .data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/MNIST/raw/t10k-images-idx3-ubyte.gz to .data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to .data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.76MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/MNIST/raw/t10k-labels-idx1-ubyte.gz to .data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define cnnn model # __init__ setsup the layers,\n",
        "# define cnnn model # __init__ setsup the layers,\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "   def __init__(self):\n",
        "     super(SimpleCNN, self).__init__() # init set up the layers\n",
        "     self.conv1 = nn.Conv2d(1,32,kernel_size=3, stride=1,padding=1) # 1 is the input channel , 32 number of filters k     self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=1)\n",
        "     self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "     self.fc1=nn.Linear(64*7*7,128)   # to help model to lern we ned to mulltiple\n",
        "     self.fc2 = nn.Linear(128,10)\n",
        "\n",
        "\n",
        "\n",
        "     self.conv1 = nn.Conv2d(1,32,kernel_size=3, stride=1,padding=1)\n",
        "     self.conv2 = nn.Conv2d(32, 64,kernal_size=32, stride=1, padding=1)\n",
        "     self.pool = nn.Maxpool2d(kernel_size=2,stride=2)\n",
        "     self.fc1=nn.Linear(64*7**7,128)\n",
        "     self.fc2 = nn.Linear(128,10)   # 10 categories output , 128 neuron , fc fully connected layers\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "deMfbPdHyhd7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):  # pass the data through the network\n",
        "  x=self.pool(torch.relu(self.conv1(x)))\n",
        "  x=self.pool(torch.relu(self.conv2))\n",
        "  x=x.view(-1,64*7*7) # -1 adjust the batch size  # converts the 3d fetures maps into 1 d array ( a flat list numbers)\n",
        "  x=torch.relu(self.fc1(x))\n",
        "  x=self.fc2(x)\n",
        "  return x\n",
        "\n",
        "  # self pool means apllies max pool to reduce the size of   64 feature maps * 7 pixels (height) * 7 pixels (width) = 3136"
      ],
      "metadata": {
        "id": "RC3sgkkYJr5l"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "\n",
        "def train_model(model,train_loader, criterion, optimizer, num_epochs=2):\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for image, labels in train_loader:\n",
        "      optimizer.zero_glad()\n",
        "      outputs = model(images)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "JuEXm_my_SS-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model,test_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data,1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()"
      ],
      "metadata": {
        "id": "L_yseQlKRn1S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "i_iJkxAmSMDk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "source": [
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "rCDFfvxDSoof"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__() # init set up the layers\n",
        "        self.conv1 = nn.Conv2d(1,32,kernel_size=3, stride=1,padding=1) # 1 is the input channel , 32 number of filters k\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__() # init set up the layers\n",
        "        self.conv1 = nn.Conv2d(1,32,kernel_size=3, stride=1,padding=1) # 1 is the input channel , 32 number of filters k\n",
        "        self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_njRgWrrS2TU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, criterion, optimizer, num_epochs=2)\n",
        "test_model(model, test_loader)\n"
      ],
      "metadata": {
        "id": "Up7dSrfgS_Al"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Assuming SimpleCNN is defined as in previous code examples\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()  # init set up the layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # 1 is the input channel , 32 number of filters k\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "# Define and initialize model, criterion, and optimizer in the same cell before calling train_model and test_model\n",
        "model = SimpleCNN()  # This line initializes the model\n",
        "criterion = nn.CrossEntropyLoss()  # Measures classification loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer with learning rate 0.001\n",
        "\n",
        "# This part needs to be defined first so 'model', 'criterion', and 'optimizer' are in scope\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=2):\n",
        "    # Implement your training logic here\n",
        "    pass\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    # Implement your testing logic here\n",
        "    pass\n",
        "\n",
        "# Assuming train_loader and test_loader are defined elsewhere in the script\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=2) # call the train_model\n",
        "test_model(model, test_loader) # call the test_model"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QnAFZD6TMaL",
        "outputId": "dc2eb52e-f49e-455a-ce8f-f7b5f04d6817"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=2):\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0  # To track total loss for the epoch\n",
        "        for images, labels in train_loader:\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print loss after each epoch\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "GNcSaPogTATk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # No need to calculate gradients during testing\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)  # Get class with highest probability\n",
        "            total += labels.size(0)  # Count total samples\n",
        "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
        "\n",
        "    # Print accuracy\n",
        "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "ND03i7WsUTM6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))  # Convolution + ReLU + Pooling\n",
        "    x = self.pool(torch.relu(self.conv2(x)))  # Convolution + ReLU + Pooling\n",
        "    x = x.view(-1, 64 * 7 * 7)  # Flattening the data\n",
        "    x = torch.relu(self.fc1(x))  # First fully connected layer\n",
        "    x = self.fc2(x)  # Second fully connected layer\n",
        "    return x  # Make sure this returns the output tensor\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u0Bw4E_bUYun"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "source": [
        "def forward(self, x):\n",
        "    pass"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "MDPvT6CCUvM3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the convolutional layers and apply an activation function\n",
        "        x = torch.relu(self.conv1(x))  # Apply ReLU activation after conv1\n",
        "        x = torch.relu(self.conv2(x))  # Apply ReLU activation after conv2\n",
        "        return x  # Return the output tensor"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XW-mlWjEUwvg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()  # Replace SimpleCNN with your actual model class name\n"
      ],
      "metadata": {
        "id": "dEedv_UxUf48"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    print(images.shape)  # Should be (batch_size, 1, 28, 28) for MNIST\n",
        "    print(labels.shape)  # Should be (batch_size,)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwEnR53nV0yH",
        "outputId": "2a5358ec-fbdb-4678-eee6-43112708af5b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(images)  # Pass the batch of images through the model\n",
        "print(outputs)  # Print the outputs\n",
        "print(outputs.shape)  # Check the shape of the outputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umw5Zsz2V5kX",
        "outputId": "2ab72fd0-f402-4516-9023-c935ee369a24"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.2161, 0.1700, 0.1390,  ..., 0.1390, 0.1057, 0.0439],\n",
            "          [0.3483, 0.3379, 0.3171,  ..., 0.3171, 0.3176, 0.1228],\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          ...,\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          [0.3784, 0.3664, 0.3764,  ..., 0.3764, 0.3224, 0.1371],\n",
            "          [0.2003, 0.2098, 0.2442,  ..., 0.2442, 0.2333, 0.1756]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0736, 0.1165, 0.1594,  ..., 0.1594, 0.1923, 0.1094],\n",
            "          [0.1030, 0.2429, 0.2410,  ..., 0.2410, 0.2233, 0.1730],\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          ...,\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          [0.0796, 0.1334, 0.1504,  ..., 0.1504, 0.1194, 0.1143],\n",
            "          [0.0000, 0.0432, 0.0357,  ..., 0.0357, 0.0000, 0.0310]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.2342, 0.1919, 0.1941,  ..., 0.1941, 0.1696, 0.1384],\n",
            "          [0.2918, 0.2876, 0.3662,  ..., 0.3662, 0.3526, 0.2101],\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          ...,\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          [0.3610, 0.3401, 0.4039,  ..., 0.4039, 0.3068, 0.2662],\n",
            "          [0.2275, 0.1735, 0.2061,  ..., 0.2061, 0.1728, 0.1024]],\n",
            "\n",
            "         [[0.0214, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0852, 0.0184, 0.0059,  ..., 0.0059, 0.0000, 0.0000],\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          [0.0920, 0.0072, 0.0174,  ..., 0.0174, 0.0000, 0.0000],\n",
            "          [0.1372, 0.0719, 0.0712,  ..., 0.0712, 0.0000, 0.0075]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0044, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0443, 0.0054, 0.0122,  ..., 0.0122, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.2161, 0.1700, 0.1390,  ..., 0.1390, 0.1057, 0.0439],\n",
            "          [0.3483, 0.3379, 0.3171,  ..., 0.3171, 0.3176, 0.1228],\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          ...,\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          [0.3784, 0.3664, 0.3764,  ..., 0.3764, 0.3224, 0.1371],\n",
            "          [0.2003, 0.2098, 0.2442,  ..., 0.2442, 0.2333, 0.1756]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0736, 0.1165, 0.1594,  ..., 0.1594, 0.1923, 0.1094],\n",
            "          [0.1030, 0.2429, 0.2410,  ..., 0.2410, 0.2233, 0.1730],\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          ...,\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          [0.0796, 0.1334, 0.1504,  ..., 0.1504, 0.1194, 0.1143],\n",
            "          [0.0000, 0.0432, 0.0357,  ..., 0.0357, 0.0000, 0.0310]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.2342, 0.1919, 0.1941,  ..., 0.1941, 0.1696, 0.1384],\n",
            "          [0.2918, 0.2876, 0.3662,  ..., 0.3662, 0.3526, 0.2101],\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          ...,\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          [0.3610, 0.3401, 0.4039,  ..., 0.4039, 0.3068, 0.2662],\n",
            "          [0.2275, 0.1735, 0.2061,  ..., 0.2061, 0.1728, 0.1024]],\n",
            "\n",
            "         [[0.0214, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0852, 0.0184, 0.0059,  ..., 0.0059, 0.0000, 0.0000],\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          [0.0920, 0.0072, 0.0174,  ..., 0.0174, 0.0000, 0.0000],\n",
            "          [0.1372, 0.0719, 0.0712,  ..., 0.0712, 0.0000, 0.0075]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0044, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0443, 0.0054, 0.0122,  ..., 0.0122, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.2161, 0.1700, 0.1390,  ..., 0.1390, 0.1057, 0.0439],\n",
            "          [0.3483, 0.3379, 0.3171,  ..., 0.3171, 0.3176, 0.1228],\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          ...,\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          [0.3784, 0.3664, 0.3764,  ..., 0.3764, 0.3224, 0.1371],\n",
            "          [0.2003, 0.2098, 0.2442,  ..., 0.2442, 0.2333, 0.1756]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0736, 0.1165, 0.1594,  ..., 0.1594, 0.1923, 0.1094],\n",
            "          [0.1030, 0.2429, 0.2410,  ..., 0.2410, 0.2233, 0.1730],\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          ...,\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          [0.0796, 0.1334, 0.1504,  ..., 0.1504, 0.1194, 0.1143],\n",
            "          [0.0000, 0.0432, 0.0357,  ..., 0.0357, 0.0000, 0.0310]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.2342, 0.1919, 0.1941,  ..., 0.1941, 0.1696, 0.1384],\n",
            "          [0.2918, 0.2876, 0.3662,  ..., 0.3662, 0.3526, 0.2101],\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          ...,\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          [0.3610, 0.3401, 0.4039,  ..., 0.4039, 0.3068, 0.2662],\n",
            "          [0.2275, 0.1735, 0.2061,  ..., 0.2061, 0.1728, 0.1024]],\n",
            "\n",
            "         [[0.0214, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0852, 0.0184, 0.0059,  ..., 0.0059, 0.0000, 0.0000],\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          [0.0920, 0.0072, 0.0174,  ..., 0.0174, 0.0000, 0.0000],\n",
            "          [0.1372, 0.0719, 0.0712,  ..., 0.0712, 0.0000, 0.0075]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0044, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0443, 0.0054, 0.0122,  ..., 0.0122, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.2161, 0.1700, 0.1390,  ..., 0.1390, 0.1057, 0.0439],\n",
            "          [0.3483, 0.3379, 0.3171,  ..., 0.3171, 0.3176, 0.1228],\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          ...,\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          [0.3784, 0.3664, 0.3764,  ..., 0.3764, 0.3224, 0.1371],\n",
            "          [0.2003, 0.2098, 0.2442,  ..., 0.2442, 0.2333, 0.1756]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0736, 0.1165, 0.1594,  ..., 0.1594, 0.1923, 0.1094],\n",
            "          [0.1030, 0.2429, 0.2410,  ..., 0.2410, 0.2233, 0.1730],\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          ...,\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          [0.0796, 0.1334, 0.1504,  ..., 0.1504, 0.1194, 0.1143],\n",
            "          [0.0000, 0.0432, 0.0357,  ..., 0.0357, 0.0000, 0.0310]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.2342, 0.1919, 0.1941,  ..., 0.1941, 0.1696, 0.1384],\n",
            "          [0.2918, 0.2876, 0.3662,  ..., 0.3662, 0.3526, 0.2101],\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          ...,\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          [0.3610, 0.3401, 0.4039,  ..., 0.4039, 0.3068, 0.2662],\n",
            "          [0.2275, 0.1735, 0.2061,  ..., 0.2061, 0.1728, 0.1024]],\n",
            "\n",
            "         [[0.0214, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0852, 0.0184, 0.0059,  ..., 0.0059, 0.0000, 0.0000],\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          [0.0920, 0.0072, 0.0174,  ..., 0.0174, 0.0000, 0.0000],\n",
            "          [0.1372, 0.0719, 0.0712,  ..., 0.0712, 0.0000, 0.0075]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0044, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0443, 0.0054, 0.0122,  ..., 0.0122, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.2161, 0.1700, 0.1390,  ..., 0.1390, 0.1057, 0.0439],\n",
            "          [0.3483, 0.3379, 0.3171,  ..., 0.3171, 0.3176, 0.1228],\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          ...,\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          [0.3784, 0.3664, 0.3764,  ..., 0.3764, 0.3224, 0.1371],\n",
            "          [0.2003, 0.2098, 0.2442,  ..., 0.2442, 0.2333, 0.1756]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0736, 0.1165, 0.1594,  ..., 0.1594, 0.1923, 0.1094],\n",
            "          [0.1030, 0.2429, 0.2410,  ..., 0.2410, 0.2233, 0.1730],\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          ...,\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          [0.0796, 0.1334, 0.1504,  ..., 0.1504, 0.1194, 0.1143],\n",
            "          [0.0000, 0.0432, 0.0357,  ..., 0.0357, 0.0000, 0.0310]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.2342, 0.1919, 0.1941,  ..., 0.1941, 0.1696, 0.1384],\n",
            "          [0.2918, 0.2876, 0.3662,  ..., 0.3662, 0.3526, 0.2101],\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          ...,\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          [0.3610, 0.3401, 0.4039,  ..., 0.4039, 0.3068, 0.2662],\n",
            "          [0.2275, 0.1735, 0.2061,  ..., 0.2061, 0.1728, 0.1024]],\n",
            "\n",
            "         [[0.0214, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0852, 0.0184, 0.0059,  ..., 0.0059, 0.0000, 0.0000],\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          [0.0920, 0.0072, 0.0174,  ..., 0.0174, 0.0000, 0.0000],\n",
            "          [0.1372, 0.0719, 0.0712,  ..., 0.0712, 0.0000, 0.0075]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0044, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0443, 0.0054, 0.0122,  ..., 0.0122, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.2161, 0.1700, 0.1390,  ..., 0.1390, 0.1057, 0.0439],\n",
            "          [0.3483, 0.3379, 0.3171,  ..., 0.3171, 0.3176, 0.1228],\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          ...,\n",
            "          [0.3408, 0.3429, 0.3234,  ..., 0.3234, 0.2808, 0.1407],\n",
            "          [0.3784, 0.3664, 0.3764,  ..., 0.3764, 0.3224, 0.1371],\n",
            "          [0.2003, 0.2098, 0.2442,  ..., 0.2442, 0.2333, 0.1756]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0736, 0.1165, 0.1594,  ..., 0.1594, 0.1923, 0.1094],\n",
            "          [0.1030, 0.2429, 0.2410,  ..., 0.2410, 0.2233, 0.1730],\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          ...,\n",
            "          [0.0754, 0.2232, 0.2204,  ..., 0.2204, 0.2060, 0.1667],\n",
            "          [0.0796, 0.1334, 0.1504,  ..., 0.1504, 0.1194, 0.1143],\n",
            "          [0.0000, 0.0432, 0.0357,  ..., 0.0357, 0.0000, 0.0310]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.2342, 0.1919, 0.1941,  ..., 0.1941, 0.1696, 0.1384],\n",
            "          [0.2918, 0.2876, 0.3662,  ..., 0.3662, 0.3526, 0.2101],\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          ...,\n",
            "          [0.3322, 0.2869, 0.3544,  ..., 0.3544, 0.2960, 0.2233],\n",
            "          [0.3610, 0.3401, 0.4039,  ..., 0.4039, 0.3068, 0.2662],\n",
            "          [0.2275, 0.1735, 0.2061,  ..., 0.2061, 0.1728, 0.1024]],\n",
            "\n",
            "         [[0.0214, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0852, 0.0184, 0.0059,  ..., 0.0059, 0.0000, 0.0000],\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0815, 0.0045, 0.0010,  ..., 0.0010, 0.0000, 0.0000],\n",
            "          [0.0920, 0.0072, 0.0174,  ..., 0.0174, 0.0000, 0.0000],\n",
            "          [0.1372, 0.0719, 0.0712,  ..., 0.0712, 0.0000, 0.0075]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0044, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0443, 0.0054, 0.0122,  ..., 0.0122, 0.0000, 0.0000]]]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "torch.Size([32, 64, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))\n",
        "    x = self.pool(torch.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 64 * 7 * 7)\n",
        "def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))\n",
        "    x = self.pool(torch.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 64 * 7 * 7)\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x  # This line is not indented properly, so it’s outside the function.\n",
        "\n"
      ],
      "metadata": {
        "id": "E2rZgCGbWEg_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Pass a batch of random input data (e.g., 32 images of size 28x28)\n",
        "dummy_input = torch.randn(32, 1, 28, 28)  # Batch size=32, 1 channel, 28x28 image size\n",
        "output = model(dummy_input)\n",
        "\n",
        "# Print the shape of the output\n",
        "print(output.shape)  # Should be (32, 10) for 32 images and 10 output classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdA2QyeRWJHg",
        "outputId": "83a80c50-4bce-4f1f-8160-02652b60041f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDe4VoCyYP-g"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    outputs = model(images)\n",
        "    print(f\"Model output shape: {outputs.shape}\")  # Should be [batch_size, 10]\n",
        "    print(f\"Labels shape: {labels.shape}\")  # Should be [batch_size]\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DcY3Td0YY7n",
        "outputId": "91331bb3-f7f1-4254-d691-2b7197ed04de"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output shape: torch.Size([32, 64, 28, 28])\n",
            "Labels shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Labels: {labels}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMCL7tVIYqi4",
        "outputId": "ce0af290-75f8-4916-ab26-2b0e4787632f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: tensor([1, 4, 8, 2, 7, 6, 4, 0, 8, 2, 3, 7, 3, 7, 9, 9, 9, 4, 0, 7, 0, 7, 5, 9,\n",
            "        7, 7, 3, 9, 4, 4, 8, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=2):\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            if outputs is None:\n",
        "                raise RuntimeError(\"Model is returning None! Check the forward method.\")\n",
        "\n",
        "            # Check the shape of outputs and labels\n",
        "            print(f\"Outputs shape: {outputs.shape}, Labels shape: {labels.shape}\")\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "jOoLE6t1YvJu"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4tD-NEr4Y1Yy"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):  # Example model class\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        # ... (other layers)\n",
        "        self.fc2 = nn.Linear(128, 10)  # Now within the class\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ... (forward logic using self.fc2)\n",
        "        pass"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oDrM_P0OY9XO"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "qGKHqxTuY5Ui"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):  # Example model class\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        # ... (other layers)\n",
        "        self.fc2 = nn.Linear(128, 10)  # Now within the class\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ... (forward logic using self.fc2)\n",
        "        # Assuming x is the input to the model\n",
        "        # ... (other layers and operations)\n",
        "\n",
        "        # Make sure the output is flattened and passed through the final linear layer\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.fc2(x)  # Apply the final linear layer for classification\n",
        "\n",
        "        return x # Return the output"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "CEaIcakaZMSG"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))  # Convolution + ReLU + Pooling\n",
        "    x = self.pool(torch.relu(self.conv2(x)))  # Convolution + ReLU + Pooling\n",
        "    x = x.view(-1, 64 * 7 * 7)  # Flatten the 3D tensor to 1D (batch_size, 64 * 7 * 7)\n",
        "    x = torch.relu(self.fc1(x))  # Pass through the first fully connected layer\n",
        "    x = self.fc2(x)  # Pass through the second fully connected layer\n",
        "    return x  # Final predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "2qF5tuwGZFB7"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(images)\n",
        "print(f\"Outputs shape: {outputs.shape}\")  # Expected: [32, 10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVrw0QEYZtIa",
        "outputId": "16f636fc-9ec3-4956-a461-b24a98c6d5de"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs shape: torch.Size([32, 64, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Outputs shape: {outputs.shape}\")  # Should be [batch_size, 10]\n",
        "print(f\"Labels shape: {labels.shape}\")  # Should be [batch_size]\n",
        "print(f\"Labels: {labels}\")  # Check the values of labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2FHg9bMaA0g",
        "outputId": "18cb4f0c-2661-4013-82a3-23925689f92c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs shape: torch.Size([32, 64, 28, 28])\n",
            "Labels shape: torch.Size([32])\n",
            "Labels: tensor([3, 6, 0, 5, 1, 6, 4, 0, 7, 6, 6, 9, 7, 9, 7, 6, 9, 5, 1, 1, 4, 0, 0, 4,\n",
            "        7, 8, 7, 2, 9, 9, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))  # Convolution + ReLU + Pooling\n",
        "    x = self.pool(torch.relu(self.conv2(x)))  # Convolution + ReLU + Pooling\n",
        "    x = x.view(-1, 64 * 7 * 7)  # Flatten the 3D tensor to 1D\n",
        "    x = torch.relu(self.fc1(x))  # Fully connected layer 1\n",
        "    x = self.fc2(x)  # Fully connected layer 2 (logits for 10 classes)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "E7nSa0nuaGvw"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(images)\n",
        "print(f\"Outputs shape: {outputs.shape}\")  # Should be [32, 10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udSzZRdJaWj2",
        "outputId": "a68e772a-307e-4e3d-d177-0136592fd8ed"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs shape: torch.Size([32, 64, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Labels: {labels}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKdw3NK0aY1j",
        "outputId": "80ccc609-d445-45e2-f7a1-09a1970a83bf"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: tensor([3, 6, 0, 5, 1, 6, 4, 0, 7, 6, 6, 9, 7, 9, 7, 6, 9, 5, 1, 1, 4, 0, 0, 4,\n",
            "        7, 8, 7, 2, 9, 9, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n"
      ],
      "metadata": {
        "id": "Pfhq_aVeabqr"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels.squeeze()  # Remove extra dimensions if necessary\n"
      ],
      "metadata": {
        "id": "6DnEYrq3ad4V"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Jv60oH1ahLq"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "id": "ojuoW2measop"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "id": "Hl_bVu_0ayh8"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "id": "vip8yoxUa32v"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Data Loading and Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values between -1 and 1\n",
        "])\n",
        "\n",
        "# Load training and testing datasets\n",
        "train_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_data = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "# Step 2: Define the CNN Model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten the feature maps\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Step 3: Initialize Model, Loss, and Optimizer\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()  # Loss for classification tasks\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 4: Define Training Function\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=2):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            outputs = model(images)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Calculate loss\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update model weights\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print average loss for the epoch\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Step 5: Define Testing Function\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "# Step 6: Train and Test the Model\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=2)\n",
        "test_model(model, test_loader)\n",
        "\n",
        "# Step 7: Visualize Predictions\n",
        "def visualize_predictions(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    images, labels = next(iter(test_loader))  # Get a batch of test data\n",
        "    outputs = model(images)  # Get model predictions\n",
        "    _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
        "\n",
        "    # Plot the first 10 images with predictions\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i in range(10):\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')  # Show the image\n",
        "        plt.title(f\"True: {labels[i].item()}, Pred: {predicted[i].item()}\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "VZ029ZuXakr4",
        "outputId": "c85917db-eb03-4b1b-ff4e-b15fdbed2e6f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Loss: 0.1293\n",
            "Epoch 2/2, Loss: 0.0428\n",
            "Accuracy: 98.81%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}